{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/chrischen/anaconda/envs/py27/lib/python2.7/site-packages/pocketsphinx/model',\n",
       " '/Users/chrischen/anaconda/envs/py27/lib/python2.7/site-packages/pocketsphinx/data')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import environ, path\n",
    "import os\n",
    "from pocketsphinx.pocketsphinx import *\n",
    "from sphinxbase.sphinxbase import *\n",
    "\n",
    "from pocketsphinx import DefaultConfig, Decoder, get_model_path, get_data_path\n",
    "\n",
    "MODELDIR = get_model_path()\n",
    "DATADIR = get_data_path()\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import *\n",
    "\n",
    "MODELDIR,DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Phonemes: ', ['SIL', 'T', 'T', 'UW', 'SIL'])\n"
     ]
    }
   ],
   "source": [
    "# Create a decoder with certain model\n",
    "config = Decoder.default_config()\n",
    "config.set_string('-hmm', os.path.join(MODELDIR, 'en-us-adapt'))\n",
    "config.set_string('-allphone', os.path.join(MODELDIR, 'chess-phone.lm.bin'))\n",
    "config.set_string('-dict', '/Users/chrischen/CS182/wechess-ai/chess-project.dic')\n",
    "config.set_float('-lw', 2.0)\n",
    "config.set_float('-beam', 1e-10)\n",
    "config.set_float('-pbeam', 1e-10)\n",
    "\n",
    "# Decode streaming data.\n",
    "decoder = Decoder(config)\n",
    "\n",
    "decoder.start_utt()\n",
    "stream = open('/Users/chrischen/CS182/wechess-ai/wav/2_26.wav', 'rb')\n",
    "i=0\n",
    "while True:\n",
    "    buf = stream.read(1024)\n",
    "    if buf:\n",
    "        decoder.process_raw(buf, False, False)\n",
    "    else:\n",
    "        break\n",
    "decoder.end_utt()\n",
    "\n",
    "hypothesis = decoder.hyp()\n",
    "print ('Phonemes: ', [seg.word for seg in decoder.seg()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_phonemes(file):\n",
    "    # Decode streaming data\n",
    "    decoder = Decoder(config)\n",
    "    decoder.start_utt()\n",
    "    stream = open(file, 'rb')\n",
    "    i=0\n",
    "    while True:\n",
    "        buf = stream.read(1024)\n",
    "        if buf:\n",
    "            decoder.process_raw(buf, False, False)\n",
    "        else:\n",
    "            break\n",
    "    decoder.end_utt()\n",
    "\n",
    "    hypothesis = decoder.hyp()\n",
    "    return [seg.word for seg in decoder.seg()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SIL', 'K', 'W', 'W', 'IY', 'NG', 'IY', 'SIL']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_phonemes(\"queen_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = [i for i in glob.glob('/Users/chrischen/CS182/wechess-ai/wav/*') if '.wav' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [00:00<00:00, 891702.43it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(file_list):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phonemes = {\n",
    "    'pawn': ['P', 'AO', 'N'],\n",
    "    'knight': ['N', 'AY', 'T'],\n",
    "    'bishop': ['B', 'IH', 'SH', 'AH', 'P'],\n",
    "    'rook': ['R', 'UH', 'K'],\n",
    "    'queen': ['K', 'W', 'IY', 'N'],\n",
    "    'king': ['K', 'IH', 'NG'],\n",
    "    'takes': ['T', 'EY', 'K', 'S'],\n",
    "    'castle': ['K', 'AE', 'S', 'AH', 'L'],\n",
    "    '1': ['W', 'AH', 'N'],\n",
    "    '2': ['T', 'UW'],\n",
    "    '3': ['TH', 'R', 'IY'],\n",
    "    '4': ['F', 'AO', 'R'],\n",
    "    '5': ['F', 'AY', 'V'],\n",
    "    '6': ['S', 'IH', 'K', 'S'],\n",
    "    '7': ['S', 'EH', 'V', 'AH', 'N'],\n",
    "    '8': ['EY', 'T'],\n",
    "    'a': ['EY'],\n",
    "    'b': ['B', 'IY'],\n",
    "    'c': ['S', 'IY'],\n",
    "    'd': ['D', 'IY'],\n",
    "    'e': ['IY'],\n",
    "    'f': ['EH', 'F'],\n",
    "    'g': ['JH', 'IY'],\n",
    "    'h': ['EY', 'CH'],\n",
    "    'kingside': ['K', 'IH', 'NG', 'S', 'AY', 'D'],\n",
    "    'queenside': ['K', 'W', 'IY', 'N', 'S', 'AY', 'D'],\n",
    "    'to': ['T', 'UW'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1350it [19:41,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# import phonemes of training sets\n",
    "training_set = {}\n",
    "for f in file_names:\n",
    "    training_set[f] = []\n",
    "    \n",
    "# for each file name\n",
    "\n",
    "def get_phoneme_pool(filepath):\n",
    "    return (filepath.split('/wav/')[1].split('_')[0], get_phonemes(filepath))\n",
    "    \n",
    "pool_party = Pool(processes=2)\n",
    "\n",
    "for res in tqdm(pool_party.imap_unordered(get_phoneme_pool, file_list)):\n",
    "    training_set[res[0]].append(res[1])\n",
    "\n",
    "\n",
    "    \n",
    "# for name in file_names:\n",
    "#     training_set[name] = []\n",
    "#     # import phonemes for all 50 files with that file name\n",
    "#     for i in range(1, 51):\n",
    "#         training_set[name].append(get_phonemes(name + '_' + str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('training_set.pickle', 'wb') as handle:\n",
    "    pickle.dump(training_set, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piece_names = ['king', 'queen', 'knight', 'bishop', 'rook', 'pawn']\n",
    "files = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "ranks = map(str, range(1,9))\n",
    "actions = ['to', 'takes', 'castle', 'kingside', 'queenside']\n",
    "indices_to_words = {}\n",
    "words = piece_names + files + ranks + actions\n",
    "for index, word in enumerate(words):\n",
    "    indices_to_words[index] = (word, len(phonemes[word]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ('king', 3),\n",
       " 1: ('queen', 4),\n",
       " 2: ('knight', 3),\n",
       " 3: ('bishop', 5),\n",
       " 4: ('rook', 3),\n",
       " 5: ('pawn', 3),\n",
       " 6: ('a', 1),\n",
       " 7: ('b', 2),\n",
       " 8: ('c', 2),\n",
       " 9: ('d', 2),\n",
       " 10: ('e', 1),\n",
       " 11: ('f', 2),\n",
       " 12: ('g', 2),\n",
       " 13: ('h', 2),\n",
       " 14: ('1', 3),\n",
       " 15: ('2', 2),\n",
       " 16: ('3', 3),\n",
       " 17: ('4', 3),\n",
       " 18: ('5', 3),\n",
       " 19: ('6', 4),\n",
       " 20: ('7', 5),\n",
       " 21: ('8', 2),\n",
       " 22: ('to', 2),\n",
       " 23: ('takes', 4),\n",
       " 24: ('castle', 5),\n",
       " 25: ('kingside', 6),\n",
       " 26: ('queenside', 7)}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_to_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transition_probabilities = [[0 for _ in range(27)] for _ in range(27)]\n",
    "\n",
    "# set the transition probability of each word to itself to be n/n+1 where n is the number of \n",
    "# phonemes for the word\n",
    "for index in range(27):\n",
    "    _, n = indices_to_words[index]\n",
    "    transition_probabilities[index][index] = n * 1.0 / (n + 1)\n",
    "\n",
    "# pieces are indices 0-5 and always transition to a file aka letter (indices 6-13)\n",
    "for i in range(6):\n",
    "    _, n = indices_to_words[i]\n",
    "    trans_prob = 1.0 / (n + 1)\n",
    "    for j in range(6, 14):\n",
    "        transition_probabilities[i][j] += trans_prob * 1.0 / 8\n",
    "\n",
    "# letters are indices 6 - 13 and always transition to numbers (indices 14-21)\n",
    "for i in range(6, 14):\n",
    "    _, n = indices_to_words[i]\n",
    "    trans_prob = 1.0 / (n + 1)\n",
    "    for j in range(14, 22):\n",
    "        transition_probabilities[i][j] += trans_prob * 1.0 / 8\n",
    "\n",
    "# numbers are indices 14-21 and transition 50% of the time to actions\n",
    "# (indices 22 - 23)\n",
    "for i in range(14, 22):\n",
    "    _, n = indices_to_words[i]\n",
    "    trans_prob = 1.0 / (n + 1)\n",
    "    for j in range(14, 22):    \n",
    "        transition_probabilities[i][j] += trans_prob * 0.5 / 8\n",
    "    for j in [22, 23]:\n",
    "        transition_probabilities[i][j] += trans_prob * 0.5 / 2\n",
    "\n",
    "# actions are indices 22-23 and always transition to letters (indices 6 - 13)\n",
    "for i in [22, 23]:\n",
    "    _, n = indices_to_words[i]\n",
    "    trans_prob = 1.0 / (n + 1)\n",
    "    for j in range(6, 14):\n",
    "        transition_probabilities[i][j] += trans_prob * 1.0 / 8\n",
    "\n",
    "# castling is index 24 and always transitions to (king/queen)side (indices 25-26)\n",
    "trans_prob = 1.0 / 6\n",
    "for j in [25, 26]:\n",
    "    transition_probabilities[24][j] += trans_prob * 1.0 / 2\n",
    "\n",
    "# (king/queen)side always transitions to (king/queen)side\n",
    "for i in [25, 26]:\n",
    "    trans_prob = 1.0 / (indices_to_words[i][1] + 1)\n",
    "    transition_probabilities[i][i] += trans_prob     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pawn',\n",
       " 'queen',\n",
       " 'kingside',\n",
       " 'bishop',\n",
       " 'takes',\n",
       " '1',\n",
       " 'to',\n",
       " '3',\n",
       " '2',\n",
       " '5',\n",
       " '4',\n",
       " '7',\n",
       " '6',\n",
       " '9',\n",
       " '8',\n",
       " 'b',\n",
       " 'a',\n",
       " 'king',\n",
       " 'c',\n",
       " 'rook',\n",
       " 'e',\n",
       " 'd',\n",
       " 'g',\n",
       " 'f',\n",
       " 'knight',\n",
       " 'queenside',\n",
       " 'h',\n",
       " 'castle',\n",
       " 'side']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename(dir, pattern, titlePattern):\n",
    "    for pathAndFilename in glob.iglob(os.path.join(dir, pattern)):\n",
    "        title, ext = os.path.splitext(os.path.basename(pathAndFilename))\n",
    "        print(os.path.join(dir, titlePattern % title + ext))\n",
    "        os.rename(pathAndFilename, \n",
    "                  os.path.join(dir, titlePattern % title + ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rename(r'/Users/apple/Desktop/16-17/CS182/chess-project/wav2', r'*.wav', r'%sb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOPHIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from pocketsphinx.pocketsphinx import *\n",
    "from sphinxbase.sphinxbase import *\n",
    "\n",
    "import os\n",
    "import pyaudio\n",
    "import wave\n",
    "import audioop\n",
    "from collections import deque\n",
    "import time\n",
    "import math\n",
    "\n",
    "from pocketsphinx import DefaultConfig, Decoder, get_model_path, get_data_path\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Written by Sophie Li, 2016\n",
    "http://blog.justsophie.com/python-speech-to-text-with-pocketsphinx/\n",
    "\"\"\"\n",
    "\n",
    "class SpeechDetector:\n",
    "    def __init__(self):\n",
    "        # Microphone stream config.\n",
    "        self.CHUNK = 1024  # CHUNKS of bytes to read each time from mic\n",
    "        self.FORMAT = pyaudio.paInt16\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 16000\n",
    "\n",
    "        self.SILENCE_LIMIT = 1  # Silence limit in seconds. The max ammount of seconds where\n",
    "                           # only silence is recorded. When this time passes the\n",
    "                           # recording finishes and the file is decoded\n",
    "\n",
    "        self.PREV_AUDIO = 0.5  # Previous audio (in seconds) to prepend. When noise\n",
    "                          # is detected, how much of previously recorded audio is\n",
    "                          # prepended. This helps to prevent chopping the beginning\n",
    "                          # of the phrase.\n",
    "\n",
    "        self.THRESHOLD = 4500\n",
    "        self.num_phrases = -1\n",
    "\n",
    "        # These will need to be modified according to where the pocketsphinx folder is\n",
    "        MODELDIR = get_model_path()\n",
    "        DATADIR = get_data_path()\n",
    "\n",
    "        # Create a decoder with certain model\n",
    "        config = Decoder.default_config()\n",
    "        config.set_string('-hmm', os.path.join(MODELDIR, 'en-us'))\n",
    "#         config.set_string('-lm', os.path.join(MODELDIR, 'en-us.lm.bin'))\n",
    "#         config.set_string('-dict', os.path.join(MODELDIR, 'cmudict-en-us.dict'))\n",
    "        config.set_string('-allphone', os.path.join(MODELDIR, 'chess-phone.lm.bin'))\n",
    "#         config.set_float('-lw', 2.0)\n",
    "#         config.set_float('-beam', 1e-10)\n",
    "#         config.set_float('-pbeam', 1e-10)\n",
    "\n",
    "        # Creaders decoder object for streaming data.\n",
    "        self.decoder = Decoder(config)\n",
    "\n",
    "    def setup_mic(self, num_samples=50):\n",
    "        \"\"\" Gets average audio intensity of your mic sound. You can use it to get\n",
    "            average intensities while you're talking and/or silent. The average\n",
    "            is the avg of the .2 of the largest intensities recorded.\n",
    "        \"\"\"\n",
    "        print \"Getting intensity values from mic.\"\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(format=self.FORMAT, \n",
    "                        channels=self.CHANNELS,\n",
    "                        rate=self.RATE, \n",
    "                        input=True, \n",
    "                        frames_per_buffer=self.CHUNK)\n",
    "\n",
    "        values = [math.sqrt(abs(audioop.avg(stream.read(self.CHUNK), 4)))\n",
    "                  for x in range(num_samples)]\n",
    "        values = sorted(values, reverse=True)\n",
    "        r = sum(values[:int(num_samples * 0.2)]) / int(num_samples * 0.2)\n",
    "        print \" Finished \"\n",
    "        print \" Average audio intensity is \", r\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "        if r < 3000:\n",
    "            self.THRESHOLD = 3500\n",
    "        else:\n",
    "            self.THRESHOLD = r + 100\n",
    "\n",
    "    def save_speech(self, data, p):\n",
    "        \"\"\"\n",
    "        Saves mic data to temporary WAV file. Returns filename of saved\n",
    "        file\n",
    "        \"\"\"\n",
    "        filename = 'output_'+str(int(time.time()))\n",
    "        # writes data to WAV file\n",
    "        data = ''.join(data)\n",
    "        wf = wave.open(filename + '.wav', 'wb')\n",
    "        print('save_speech...')\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "        wf.setframerate(16000)  # TODO make this value a function parameter?\n",
    "        wf.writeframes(data)\n",
    "        wf.close()\n",
    "        return filename + '.wav'\n",
    "\n",
    "    def decode_phrase(self, wav_file):\n",
    "        self.decoder.start_utt()\n",
    "        stream = open(wav_file, \"rb\")\n",
    "        while True:\n",
    "            buf = stream.read(1024)\n",
    "            if buf:\n",
    "                self.decoder.process_raw(buf, False, False)\n",
    "            else:\n",
    "                break\n",
    "        self.decoder.end_utt()\n",
    "        words = []\n",
    "        [words.append(seg.word) for seg in self.decoder.seg()]\n",
    "        return words\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Listens to Microphone, extracts phrases from it and calls pocketsphinx\n",
    "        to decode the sound\n",
    "        \"\"\"\n",
    "        self.setup_mic()\n",
    "\n",
    "        #Open stream\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(format=self.FORMAT, \n",
    "                        channels=self.CHANNELS, \n",
    "                        rate=self.RATE, \n",
    "                        input=True, \n",
    "                        frames_per_buffer=self.CHUNK)\n",
    "        print \"* Mic set up and listening. \"\n",
    "\n",
    "        audio2send = []\n",
    "        cur_data = ''  # current chunk of audio data\n",
    "        rel = self.RATE/self.CHUNK\n",
    "        slid_win = deque(maxlen=self.SILENCE_LIMIT * rel)\n",
    "        #Prepend audio from 0.5 seconds before noise was detected\n",
    "        prev_audio = deque(maxlen=self.PREV_AUDIO * rel)\n",
    "        started = False\n",
    "\n",
    "        while True:\n",
    "            cur_data = stream.read(self.CHUNK)\n",
    "            slid_win.append(math.sqrt(abs(audioop.avg(cur_data, 4))))\n",
    "            \n",
    "            thresh = sum([x > self.THRESHOLD for x in slid_win])\n",
    "#             print 'threshold:{thresh}'.format(thresh=thresh)\n",
    "            if thresh > 0:\n",
    "                if started == False:\n",
    "                    print \"Starting recording of phrase\"\n",
    "                    started = True\n",
    "                audio2send.append(cur_data)\n",
    "\n",
    "            elif started:\n",
    "                print \"Finished recording, decoding phrase\"\n",
    "                filename = self.save_speech(list(prev_audio) + audio2send, p)\n",
    "                r = self.decode_phrase(filename)\n",
    "                print \"DETECTED: \", r\n",
    "\n",
    "                # Removes temp audio file\n",
    "                os.remove(filename)\n",
    "                # Reset all\n",
    "                started = False\n",
    "                slid_win = deque(maxlen=self.SILENCE_LIMIT * rel)\n",
    "                prev_audio = deque(maxlen=0.5 * rel)\n",
    "                audio2send = []\n",
    "                print \"Listening ...\"\n",
    "\n",
    "            else:\n",
    "                prev_audio.append(cur_data)\n",
    "\n",
    "        print \"* Done listening\"\n",
    "        stream.close()\n",
    "        p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sd = SpeechDetector()\n",
    "sd.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
