{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from pocketsphinx.pocketsphinx import *\n",
    "from sphinxbase.sphinxbase import *\n",
    "\n",
    "import os\n",
    "import pyaudio\n",
    "import wave\n",
    "import audioop\n",
    "from collections import deque\n",
    "import time\n",
    "import math\n",
    "\n",
    "from pocketsphinx import DefaultConfig, Decoder, get_model_path, get_data_path\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Written by Sophie Li, 2016\n",
    "http://blog.justsophie.com/python-speech-to-text-with-pocketsphinx/\n",
    "\"\"\"\n",
    "\n",
    "class SpeechDetector:\n",
    "    def __init__(self):\n",
    "        # Microphone stream config.\n",
    "        self.CHUNK = 1024  # CHUNKS of bytes to read each time from mic\n",
    "        self.FORMAT = pyaudio.paInt16\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 16000\n",
    "\n",
    "        self.SILENCE_LIMIT = 1  # Silence limit in seconds. The max ammount of seconds where\n",
    "                           # only silence is recorded. When this time passes the\n",
    "                           # recording finishes and the file is decoded\n",
    "\n",
    "        self.PREV_AUDIO = 0.5  # Previous audio (in seconds) to prepend. When noise\n",
    "                          # is detected, how much of previously recorded audio is\n",
    "                          # prepended. This helps to prevent chopping the beginning\n",
    "                          # of the phrase.\n",
    "\n",
    "        self.THRESHOLD = 4500\n",
    "        self.num_phrases = -1\n",
    "\n",
    "        # These will need to be modified according to where the pocketsphinx folder is\n",
    "        MODELDIR = get_model_path()\n",
    "        DATADIR = get_data_path()\n",
    "\n",
    "        # Create a decoder with certain model\n",
    "        config = Decoder.default_config()\n",
    "        config.set_string('-hmm', os.path.join(MODELDIR, 'en-us'))\n",
    "#         config.set_string('-lm', os.path.join(MODELDIR, 'en-us.lm.bin'))\n",
    "#         config.set_string('-dict', os.path.join(MODELDIR, 'cmudict-en-us.dict'))\n",
    "        config.set_string('-allphone', os.path.join(MODELDIR, 'chess-phone.lm.bin'))\n",
    "        config.set_float('-lw', 2.0)\n",
    "        config.set_float('-beam', 1e-10)\n",
    "        config.set_float('-pbeam', 1e-10)\n",
    "\n",
    "        # Creaders decoder object for streaming data.\n",
    "        self.decoder = Decoder(config)\n",
    "\n",
    "    def setup_mic(self, num_samples=50):\n",
    "        \"\"\" Gets average audio intensity of your mic sound. You can use it to get\n",
    "            average intensities while you're talking and/or silent. The average\n",
    "            is the avg of the .2 of the largest intensities recorded.\n",
    "        \"\"\"\n",
    "        print \"Getting intensity values from mic.\"\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(format=self.FORMAT, \n",
    "                        channels=self.CHANNELS,\n",
    "                        rate=self.RATE, \n",
    "                        input=True, \n",
    "                        frames_per_buffer=self.CHUNK)\n",
    "\n",
    "        values = [math.sqrt(abs(audioop.avg(stream.read(self.CHUNK), 4)))\n",
    "                  for x in range(num_samples)]\n",
    "        values = sorted(values, reverse=True)\n",
    "        r = sum(values[:int(num_samples * 0.2)]) / int(num_samples * 0.2)\n",
    "        print \" Finished \"\n",
    "        print \" Average audio intensity is \", r\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "        if r < 3000:\n",
    "            self.THRESHOLD = 3500\n",
    "        else:\n",
    "            self.THRESHOLD = r + 100\n",
    "\n",
    "    def save_speech(self, data, p):\n",
    "        \"\"\"\n",
    "        Saves mic data to temporary WAV file. Returns filename of saved\n",
    "        file\n",
    "        \"\"\"\n",
    "        filename = 'output_'+str(int(time.time()))\n",
    "        # writes data to WAV file\n",
    "        data = ''.join(data)\n",
    "        wf = wave.open(filename + '.wav', 'wb')\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "        wf.setframerate(16000)  # TODO make this value a function parameter?\n",
    "        wf.writeframes(data)\n",
    "        wf.close()\n",
    "        return filename + '.wav'\n",
    "\n",
    "    def decode_phrase(self, wav_file):\n",
    "        self.decoder.start_utt()\n",
    "        stream = open(wav_file, \"rb\")\n",
    "        while True:\n",
    "            buf = stream.read(1024)\n",
    "            if buf:\n",
    "                self.decoder.process_raw(buf, False, False)\n",
    "            else:\n",
    "                break\n",
    "        self.decoder.end_utt()\n",
    "        words = []\n",
    "        [words.append(seg.word) for seg in self.decoder.seg()]\n",
    "        return words\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Listens to Microphone, extracts phrases from it and calls pocketsphinx\n",
    "        to decode the sound\n",
    "        \"\"\"\n",
    "        self.setup_mic()\n",
    "\n",
    "        #Open stream\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(format=self.FORMAT, \n",
    "                        channels=self.CHANNELS, \n",
    "                        rate=self.RATE, \n",
    "                        input=True, \n",
    "                        frames_per_buffer=self.CHUNK)\n",
    "        print \"* Mic set up and listening. \"\n",
    "\n",
    "        audio2send = []\n",
    "        cur_data = ''  # current chunk of audio data\n",
    "        rel = self.RATE/self.CHUNK\n",
    "        slid_win = deque(maxlen=self.SILENCE_LIMIT * rel)\n",
    "        #Prepend audio from 0.5 seconds before noise was detected\n",
    "        prev_audio = deque(maxlen=self.PREV_AUDIO * rel)\n",
    "        started = False\n",
    "\n",
    "        while True:\n",
    "            cur_data = stream.read(self.CHUNK)\n",
    "            slid_win.append(math.sqrt(abs(audioop.avg(cur_data, 4))))\n",
    "\n",
    "            if sum([x > self.THRESHOLD for x in slid_win]) > 0:\n",
    "                if started == False:\n",
    "                    print \"Starting recording of phrase\"\n",
    "                    started = True\n",
    "                audio2send.append(cur_data)\n",
    "\n",
    "            elif started:\n",
    "                print \"Finished recording, decoding phrase\"\n",
    "                filename = self.save_speech(list(prev_audio) + audio2send, p)\n",
    "                r = self.decode_phrase(filename)\n",
    "                print \"DETECTED: \", r\n",
    "\n",
    "                # Removes temp audio file\n",
    "                os.remove(filename)\n",
    "                # Reset all\n",
    "                started = False\n",
    "                slid_win = deque(maxlen=self.SILENCE_LIMIT * rel)\n",
    "                prev_audio = deque(maxlen=0.5 * rel)\n",
    "                audio2send = []\n",
    "                print \"Listening ...\"\n",
    "\n",
    "            else:\n",
    "                prev_audio.append(cur_data)\n",
    "\n",
    "        print \"* Done listening\"\n",
    "        stream.close()\n",
    "        p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting intensity values from mic.\n",
      " Finished \n",
      " Average audio intensity is  1124.7041918\n",
      "* Mic set up and listening. \n",
      "Starting recording of phrase\n",
      "Finished recording, decoding phrase\n",
      "DETECTED:  ['SIL', 'M', 'R', 'R', 'T', 'SIL', 'B', 'T', 'AH', 'B', 'SIL', 'AH', 'AO', 'EH', 'R', 'S', 'Z', 'AH', 'N', 'L', 'HH']\n",
      "Listening ...\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno -9981] Input overflowed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fa38f2534089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpeechDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-16ee16de321f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mcur_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mslid_win\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudioop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rdhara/anaconda/lib/python2.7/site-packages/pyaudio.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno -9981] Input overflowed"
     ]
    }
   ],
   "source": [
    "s = SpeechDetector()\n",
    "s.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
